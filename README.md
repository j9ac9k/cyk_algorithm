## Summary
`cky.py` is an implementation of the CYK (Cocke-Younger-Kasami) algorithm.  The algorithm parses string using probabilistic context free grammars (PCFG).

## Dependencies

The [BitWeight library](https://github.com/stevenbedrick/bitweight) is needed to compute the small probabilities.

## Broken Things
The `pcfg.py` files are not provided, will potentially add these in future commits once I discuss providing these files with the original authors.


## Prep: Inducing A Probabilistic Context-Free Grammar
The file `trn_02-21.cps` contains approximately 40,000 parse trees from sections 02-21 of the Wall St. Journal portion of the Penn Treebank (PTB). These trees have been processed with the following transforms:

1.  Empty nodes are removed
2.  Trees are binarized according the Collins head rules
3.  Non-terminals are annotated with their siblings and parents (v = 2, h = 2)
4.  All terminals are case-folded, and terminals tagged as proper names (`NNP`, `NNPS`) or digits (`CD`) are replaced with special tokens (`<NNP>`, `<NNPS>`, `<CD>`, respectively)

The program pcfg.py contains the PCFG class. A PCFG instance is initialized from an iterable of productions (e.g., from instances of Tree instantiated using `tree.py`). While using this class, we look up the "right hand side" (RHS) of a production, which provide the candidate "left hand sides" (LHSes) which expand to this RHS. In this implementation, there are three types of rules :

1.  The special start symbol TOP expanding to one nonterminal
2.  One nonterminal expanding to two nonterminals
3.  One preterminal expanding to one terminal

All three are represented in separate (maximum likelihood) probability distributions, the latter two conditional. The rule probabilities themselves are stored as bitweights, i.e., negative base-2 log probabilities. The BitWeight class (in `bitweight.py`) overloads unary and binary mathematical operators so that they have the same semantics as do real-valued probabilities; e.g., performing multiplication using internal log-space addition. This effectively prevents floating-point underflow. Underflow is an acute problem in PCFG parsing, as parse probabilities—formally, it is the joint probability of the sentence being generated by the grammar using the "generator story" given by the parse—are exceptionally small under any non-trivial grammar.

To create the PCFG, execute `pcfg.py`, which will read the training data (`trn_02-21.cps`) and serialize the resulting PCFG into a compressed text file `PCFG.pkl.gz`. This process will take several minutes in all, but only needs to be completed once. You do not need to turn in anything for this part of the assignment.

## The CYK Algorithm
The script `cky.py` provides a class Chart which represents a fixed-size CYK chart. It consists of a tuple of rows—representing the span size of a non-terminal at that position—each of which consists of a tuple of cells—representing a span starting at that horizontal position—and each cell is a dictionary where keys consist of a candidate non-terminal label and values are the associated probability of the production. In this implementation, unlike the lecture on CYK, the chart is the upper left-hand diagonal of a matrix; the first row contains preterminals.

Your assignment is to implement the probabilistic CYK recognition algorithm and print out the top 5 bracketed parses the first 10 sentences in `tst-100.tok`, prepended with the probability of each tree. This entails the filling of chart nodes, calculating of associated probabilities (negative base-2 log), and maintenance of backpointers to constituents. These sentences have been chosen because they are relatively short and have non-zero joint probabilities under the training PCFG.

_Tip_: The best way to begin is to start small. Rather than building a grammar out of the entire WSJ treebank and starting with a long and complex sentence, try instead to induce a grammar from a single short, simple sentence, and then try and run your CYK implementation on that. Having a small sentence that you can parse by hand and whose rules are very simple will make it much easier to debug the various off-by-one errors, etc. that will inevitably crop up, and a small and simple PCFG will make it easier to debug the math.


## Implementation
`workfile.txt` contains the output of the `cyk.py` script, which shows the best way I attempted to display the most probabilistic tree structure.


The BitWeights for the first 10 sentences are as follows:

    184.9217: <NNP> 's president and chief executive officer , <NNP> <NNP> , said the loss stems from several factors .    

    278.1779: in the <CD> third quarter , the company earned $ <CD> <CD> , or $ <CD> a share , on sales of $ <CD> <CD> .

    226.0785: we are n't going to change agencies because of a change in <NNP> . ''

    234.4429: `` the question is how much are we getting from each reader , '' said <NNP> <NNP> .

    189.0999: `` we will probably have a year-end rally , and then go down again .

    253.5285: until now , <NNP> has featured its <NNP> gossip show during the key evening period .

    188.0112: he used about <CD> words defending the witnesses ' constitutional rights .

    236.6484: in <NNP> <NNP> , <NNP> , a spokesman for the company said the analysts ' projections are `` in the ballpark . ''

    176.5634: call it the `` we 're too broke to fight '' defense .

    188.7342: certainly , the recent drop in prices does n't mean <NNP> comes cheap .


In terms of my implementation, I built a tree on the upper right matrix, with the words in the main diagonal.  In the first off-diagonal, I inserted the pre-terminal rules.  From there, I invoked the CKY algorithm to build out the rest of the matrix.  While building out the matrix, I was building out a second matrix of the same size that contained information to be used for the traceback.  Finally, for the presentation of the tree, I initialized a third matrix (resulting_chart) that contained the information that would be appended to workfile.txt.


Due to the binary nature of the CKY algorithm, implementing the traceback was equivalent of traversing through a binary tree, which is not something I have done before.  One could argue that the need for doing an actual traceback is unnecessary since I have the respective probabilities at each cell, however the terminal with the highest probability in a cell may not necessarily be the terminal used to determine the overall highest probability tree.  For this reason, the only probability evaluated is the probability at the start node.


I could write several more paragraphs about how the back-propagation worked, however the best way to describe is that I utilize a list named 'possibilities', and each element of the list contains the matrix location for a node that I have yet to evaluate, and the terminal in that node.  When I go to that node, there are two possibilities, I append both of the possibilities to the possibility list, and pursue one of them.  After I pursue one of the two possibilities, I remove that possibility from the list.  When I hit the end of the tree, I go to the last unchecked possibility and investigate.  When the length of my possibility list is 0, I know I have finished traversing the tree and exit my while loop.  In order to avoid any unforeseen errors/infinite loops (which are a possibility in a while loop), I implemented a counter that goes to len(tokens) ** 3.  Since the CKY algorithm is an O(n^3) complexity algorithm, there is no reason my counter should ever exceed len(tokens) ** 3.
